{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edfdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import gym_aloha\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# 尝试导入 LeRobot 数据集加载器\n",
    "try:\n",
    "    from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "except ImportError:\n",
    "    try:\n",
    "        from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "    except ImportError:\n",
    "        print(\"错误: 无法导入 LeRobotDataset。请确保安装了 lerobot 包 (pip install -e .)\")\n",
    "        exit(1)\n",
    "\n",
    "def verify_dataset_env_match(\n",
    "    dataset_repo_id: str,\n",
    "    env_task_name: str,\n",
    "    episode_index: int = 0,\n",
    "    output_filename: str = \"replay_verification.mp4\",\n",
    "    apply_flip_fix: bool = False,\n",
    "    max_steps: int = 400\n",
    "):\n",
    "    print(f\"Loading dataset: {dataset_repo_id}...\")\n",
    "    # 关键修复1: 强制使用 pyav 后端以避免 torchcodec 错误\n",
    "    dataset = LeRobotDataset(dataset_repo_id, video_backend=\"pyav\")\n",
    "    \n",
    "    # 关键修复2: 正确获取指定 Episode 的帧范围\n",
    "    # LeRobotDataset 是扁平的，我们需要查询元数据来找到第 N 个 Episode 在哪\n",
    "    if dataset.meta.episodes is None:\n",
    "        dataset.meta.load_metadata()\n",
    "    \n",
    "    episode_meta = dataset.meta.episodes[episode_index]\n",
    "    \n",
    "    # 获取起始和结束帧索引\n",
    "    # 注意: 这些值可能是 Tensor 也可能是 int，视版本而定，这里做统一处理\n",
    "    from_idx = episode_meta[\"dataset_from_index\"]\n",
    "    to_idx = episode_meta[\"dataset_to_index\"]\n",
    "    \n",
    "    if isinstance(from_idx, torch.Tensor): from_idx = from_idx.item()\n",
    "    if isinstance(to_idx, torch.Tensor): to_idx = to_idx.item()\n",
    "        \n",
    "    # 计算实际要播放的步数\n",
    "    num_frames = to_idx - from_idx\n",
    "    actual_steps = min(num_frames, max_steps)\n",
    "    end_idx = from_idx + actual_steps\n",
    "    \n",
    "    print(f\"Loaded Episode {episode_index}\")\n",
    "    print(f\"  - Frame Range: {from_idx} to {to_idx}\")\n",
    "    print(f\"  - Replaying: {actual_steps} steps\")\n",
    "\n",
    "    # 初始化环境\n",
    "    print(f\"Initializing environment: {env_task_name}...\")\n",
    "    env = gymnasium.make(env_task_name)\n",
    "    observation, info = env.reset()\n",
    "\n",
    "    frames = []\n",
    "    \n",
    "    # 定义 OpenPi 标准翻转掩码 (用于测试 adapt_to_pi=True 的情况)\n",
    "    # [1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1]\n",
    "    flip_mask = np.array([1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1])\n",
    "\n",
    "    print(\"Starting replay...\")\n",
    "    \n",
    "    # 逐帧遍历\n",
    "    for i, frame_idx in enumerate(range(from_idx, end_idx)):\n",
    "        # 读取单帧数据\n",
    "        item = dataset[frame_idx]\n",
    "        action = item[\"action\"]\n",
    "        \n",
    "        # 确保 action 是 numpy 数组且为 1D\n",
    "        if isinstance(action, torch.Tensor):\n",
    "            action = action.numpy()\n",
    "        \n",
    "        # --- 关键验证逻辑 ---\n",
    "        if apply_flip_fix:\n",
    "            action = action * flip_mask\n",
    "            \n",
    "        # 执行动作\n",
    "        try:\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "        except AssertionError as e:\n",
    "            print(f\"Error at step {i} (frame {frame_idx}): {e}\")\n",
    "            print(f\"Action shape: {action.shape}, Action ndim: {action.ndim}\")\n",
    "            break\n",
    "        \n",
    "        # 渲染图像 (兼容不同的 gym_aloha 版本)\n",
    "        frame = None\n",
    "        try:\n",
    "            # 尝试直接 render\n",
    "            rendered = env.render()\n",
    "            if rendered is not None and rendered.shape[2] == 3: # HWC\n",
    "                frame = rendered\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        # 如果 render 失败，尝试从 observation 获取 'top' 相机\n",
    "        if frame is None:\n",
    "            if 'pixels' in observation and 'top' in observation['pixels']:\n",
    "                cam_data = observation['pixels']['top']\n",
    "                # 转换维度 [C, H, W] -> [H, W, C]\n",
    "                if cam_data.shape[0] == 3:\n",
    "                    frame = np.transpose(cam_data, (1, 2, 0))\n",
    "                else:\n",
    "                    frame = cam_data\n",
    "\n",
    "        if frame is not None:\n",
    "            frames.append(frame.astype(np.uint8))\n",
    "            \n",
    "        if terminated or truncated:\n",
    "            print(f\"Episode terminated early by env at step {i}\")\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    # 保存视频\n",
    "    output_path = Path(output_filename)\n",
    "    if len(frames) > 0:\n",
    "        imageio.mimsave(output_path, frames, fps=30)\n",
    "        print(f\"\\n✅ 视频已保存至: {output_path.absolute()}\")\n",
    "    else:\n",
    "        print(\"\\n❌ 未能录制到任何帧。\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    if apply_flip_fix:\n",
    "        print(f\"模式: [已应用翻转修复 (Simulating adapt_to_pi=True)]\")\n",
    "        print(f\"如果此视频中机器人动作正常，说明 OpenPi 的默认设置是正确的。\")\n",
    "    else:\n",
    "        print(f\"模式: [原始数据直通 (Raw Dataset -> Env)]\")\n",
    "        print(f\"如果此视频中机器人动作正常，说明你的环境与数据集定义【完全一致】，不需要 OpenPi 的翻转。\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置\n",
    "    DATASET = \"lerobot/aloha_sim_insertion_human\"\n",
    "    ENV_TASK = \"gym_aloha/AlohaInsertion-v0\"\n",
    "    \n",
    "    # 选择你想查看的 Episode 索引 (例如 0, 1, 2...)\n",
    "    MY_EPISODE_INDEX = 5\n",
    "    \n",
    "    # 运行 1: 原始数据直通\n",
    "    verify_dataset_env_match(\n",
    "        dataset_repo_id=DATASET, \n",
    "        env_task_name=ENV_TASK, \n",
    "        episode_index=MY_EPISODE_INDEX,\n",
    "        output_filename=f\"replay_ep{MY_EPISODE_INDEX}_raw.mp4\",\n",
    "        apply_flip_fix=False\n",
    "    )\n",
    "    \n",
    "    # 运行 2: 应用翻转\n",
    "    verify_dataset_env_match(\n",
    "        dataset_repo_id=DATASET, \n",
    "        env_task_name=ENV_TASK, \n",
    "        episode_index=MY_EPISODE_INDEX,\n",
    "        output_filename=f\"replay_ep{MY_EPISODE_INDEX}_flip.mp4\",\n",
    "        apply_flip_fix=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ff314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "def extract_frames_to_images(video_path, output_dir=None):\n",
    "    \"\"\"\n",
    "    将视频逐帧保存为图片文件\n",
    "    \n",
    "    参数:\n",
    "    video_path: 视频文件路径\n",
    "    output_dir: 输出目录，如果不指定则使用视频所在目录\n",
    "    \"\"\"\n",
    "    # 检查视频文件是否存在\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"错误: 视频文件 {video_path} 不存在\")\n",
    "        return\n",
    "    \n",
    "    # 如果没有指定输出目录，则使用视频文件所在目录\n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.dirname(video_path)\n",
    "    \n",
    "    # 创建输出目录\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 打开视频文件\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 检查视频是否成功打开\n",
    "    if not cap.isOpened():\n",
    "        print(f\"错误: 无法打开视频文件 {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # 获取视频基本信息\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"视频信息:\")\n",
    "    print(f\"  - 路径: {video_path}\")\n",
    "    print(f\"  - FPS: {fps}\")\n",
    "    print(f\"  - 总帧数: {frame_count}\")\n",
    "    print(f\"  - 输出目录: {output_dir}\")\n",
    "    \n",
    "    frame_number = 0\n",
    "    \n",
    "    # 逐帧读取并保存\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 生成帧文件名\n",
    "        frame_filename = os.path.join(output_dir, f\"frame_{frame_number:04d}.png\")\n",
    "        \n",
    "        # 保存帧为PNG文件\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        \n",
    "        frame_number += 1\n",
    "        \n",
    "        # 显示进度\n",
    "        if frame_number % 30 == 0 or frame_number == frame_count:\n",
    "            print(f\"已处理 {frame_number}/{frame_count} 帧\")\n",
    "    \n",
    "    # 释放视频捕获对象\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"完成! 共保存 {frame_number} 帧到 {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 指定视频文件路径\n",
    "    video_file = \"data/aloha_sim/videos/out_0.mp4\"\n",
    "    \n",
    "    # 提取帧并保存为图片\n",
    "    extract_frames_to_images(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88779f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: lerobot/aloha_sim_insertion_human...\n",
      "Episode 0:\n",
      "  Joint positions: [ 0.   -0.96  1.16  0.   -0.3   0.    0.    0.   -0.96  1.16  0.   -0.3\n",
      "  0.    0.  ]\n",
      "\n",
      "Episode 1:\n",
      "  Joint positions: [ 0.   -0.96  1.16  0.   -0.3   0.    0.    0.   -0.96  1.16  0.   -0.3\n",
      "  0.    0.  ]\n",
      "\n",
      "Episode 2:\n",
      "  Joint positions: [ 0.   -0.96  1.16  0.   -0.3   0.    0.    0.   -0.96  1.16  0.   -0.3\n",
      "  0.    0.  ]\n",
      "\n",
      "Episode 3:\n",
      "  Joint positions: [ 0.   -0.96  1.16  0.   -0.3   0.    0.    0.   -0.96  1.16  0.   -0.3\n",
      "  0.    0.  ]\n",
      "\n",
      "Episode 4:\n",
      "  Joint positions: [ 0.   -0.96  1.16  0.   -0.3   0.    0.    0.   -0.96  1.16  0.   -0.3\n",
      "  0.    0.  ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/openpi/lib/python3.11/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import gym_aloha\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# 尝试导入 LeRobot 数据集加载器\n",
    "try:\n",
    "    from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "except ImportError:\n",
    "    try:\n",
    "        from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "    except ImportError:\n",
    "        print(\"错误: 无法导入 LeRobotDataset。请确保安装了 lerobot 包 (pip install -e .)\")\n",
    "        exit(1)\n",
    "\n",
    "def print_first_frame_joint_positions(dataset_repo_id: str, num_episodes: int = 5):\n",
    "    \"\"\"\n",
    "    打印每个episode中第一帧的关节姿态\n",
    "    \n",
    "    参数:\n",
    "    dataset_repo_id: 数据集ID\n",
    "    num_episodes: 要检查的episode数量\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset: {dataset_repo_id}...\")\n",
    "    # 强制使用 pyav 后端以避免 torchcodec 错误\n",
    "    dataset = LeRobotDataset(dataset_repo_id, video_backend=\"pyav\")\n",
    "    \n",
    "    # 加载元数据\n",
    "    if dataset.meta.episodes is None:\n",
    "        dataset.meta.load_metadata()\n",
    "    \n",
    "    # 遍历每个episode\n",
    "    for episode_index in range(min(num_episodes, len(dataset.meta.episodes))):\n",
    "        episode_meta = dataset.meta.episodes[episode_index]\n",
    "        \n",
    "        # 获取起始帧索引\n",
    "        from_idx = episode_meta[\"dataset_from_index\"]\n",
    "        if isinstance(from_idx, torch.Tensor): \n",
    "            from_idx = from_idx.item()\n",
    "        \n",
    "        # 读取第一帧数据\n",
    "        item = dataset[from_idx]\n",
    "        \n",
    "        # 打印关节位置信息\n",
    "        print(f\"Episode {episode_index}:\")\n",
    "        joint_positions = item[\"observation.state\"]\n",
    "        if isinstance(joint_positions, torch.Tensor):\n",
    "            joint_positions = joint_positions.numpy()\n",
    "        print(f\"  Joint positions: {joint_positions}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置\n",
    "    DATASET = \"lerobot/aloha_sim_insertion_human\"\n",
    "    \n",
    "    # 打印前5个episode的第一帧关节姿态\n",
    "    print_first_frame_joint_positions(DATASET, num_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2e5c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你需要修改的文件路径是: /home/user/anaconda3/envs/openpi/lib/python3.11/site-packages/gym_aloha/constants.py\n"
     ]
    }
   ],
   "source": [
    "import gym_aloha\n",
    "import os\n",
    "\n",
    "# 获取 gym_aloha 的安装路径\n",
    "package_path = os.path.dirname(gym_aloha.__file__)\n",
    "constants_path = os.path.join(package_path, 'constants.py')\n",
    "\n",
    "print(f\"你需要修改的文件路径是: {constants_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
